{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOhf8BnqTM7NWwQubHZzedb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamt2897/DL_BB/blob/main/DL_Bounding_Box.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Dependencies"
      ],
      "metadata": {
        "id": "3tKJnSmfA-C4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch torchvision\n",
        "!pip install numpy matplotlib albumentations kornia open3d gdown\n",
        "\n"
      ],
      "metadata": {
        "id": "3HMn7e87_MyT",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download & Extract Your Dataset"
      ],
      "metadata": {
        "id": "ANieU6P-BLA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download from Google Drive using gdown\n",
        "!gdown \"https://drive.google.com/uc?id=11s-GLb6LZ0SCAVW6aikqImuuQEEbT_Fb\" -O dl_challenge.tar.xz\n",
        "\n",
        "# Extract the .tar.xz file\n",
        "!tar -xvf dl_challenge.tar.xz  # This should create a dl_challenge/ directory\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "amHMCWfcBN7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "data_dir = 'dl_challenge'  # or the path where dl_challenge is located\n",
        "folders = sorted(glob.glob(os.path.join(data_dir, '*')))\n",
        "print(\"Number of data folders:\", len(folders))\n",
        "print(\"First folder name:\", folders[0])\n",
        "print(\"Files in the first folder:\", os.listdir(folders[0]))\n",
        "\n"
      ],
      "metadata": {
        "id": "-IfO0WsvDXt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset & Preprocessing**"
      ],
      "metadata": {
        "id": "dWR0za-UEWXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_path = 'dl_challenge/96e66c6d-9915-11ee-9103-bbb8eae05561'\n",
        "print(\"Files in the folder:\", os.listdir(folder_path))\n"
      ],
      "metadata": {
        "id": "q5K0nciQKBxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Loading, Model Definition & Training Setup**"
      ],
      "metadata": {
        "id": "vB5-BJNIKG4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Create a PyTorch Dataset Class"
      ],
      "metadata": {
        "id": "vInKbRiOKNTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class Sereact3DDataset(Dataset):\n",
        "    def __init__(self, folder_list, transform=None):\n",
        "        self.folder_list = folder_list\n",
        "        self.transform = transform\n",
        "\n",
        "        # Filter folders to include only those with all required files.\n",
        "        self.folder_list = [\n",
        "            folder for folder in self.folder_list\n",
        "            if all(os.path.isfile(os.path.join(folder, fname))\n",
        "                   for fname in ['rgb.jpg', 'bbox3d.npy', 'mask.npy', 'pc.npy'])\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.folder_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        folder_path = self.folder_list[idx]\n",
        "        rgb_path   = os.path.join(folder_path, 'rgb.jpg')\n",
        "        bbox_path  = os.path.join(folder_path, 'bbox3d.npy')\n",
        "        mask_path  = os.path.join(folder_path, 'mask.npy')\n",
        "        pc_path    = os.path.join(folder_path, 'pc.npy')\n",
        "\n",
        "        # Load files\n",
        "        rgb = cv2.imread(rgb_path)[:, :, ::-1]  # Convert BGR to RGB\n",
        "        bbox3d = np.load(bbox_path)\n",
        "        mask = np.load(mask_path)\n",
        "        point_cloud = np.load(pc_path)\n",
        "\n",
        "        # If the point cloud looks like an image (shape: [3, H, W]), convert it.\n",
        "        if point_cloud.ndim == 3 and point_cloud.shape[0] == 3:\n",
        "            # Convert from (3, H, W) to (H, W, 3) then flatten to (H*W, 3)\n",
        "            point_cloud = np.transpose(point_cloud, (1, 2, 0))\n",
        "            point_cloud = point_cloud.reshape(-1, 3)\n",
        "\n",
        "        # Apply transform to RGB image if provided.\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=rgb)\n",
        "            rgb = augmented['image']\n",
        "\n",
        "        # Convert to torch tensors\n",
        "        rgb = torch.from_numpy(rgb).permute(2, 0, 1).float()  # (C, H, W)\n",
        "        bbox3d = torch.from_numpy(bbox3d).float()\n",
        "        mask = torch.from_numpy(mask).float()\n",
        "        point_cloud = torch.from_numpy(point_cloud).float()  # Expected shape: [N, 3]\n",
        "\n",
        "        return {\n",
        "            'rgb': rgb,\n",
        "            'bbox3d': bbox3d,\n",
        "            'mask': mask,\n",
        "            'point_cloud': point_cloud\n",
        "        }\n"
      ],
      "metadata": {
        "id": "lHnjAKGYKH-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Transforms and Create DataLoaders**"
      ],
      "metadata": {
        "id": "5XOpEesiKVIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from torch.utils.data import DataLoader\n",
        "import albumentations as A\n",
        "\n",
        "# Define transforms for training and validation.\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "])\n",
        "val_transform = A.Compose([A.Resize(224, 224)])\n",
        "\n",
        "# Get list of folders from 'dl_challenge'\n",
        "data_dir = 'dl_challenge'\n",
        "folders = sorted(glob.glob(os.path.join(data_dir, '*')))\n",
        "\n",
        "# Example splits (adjust counts as needed)\n",
        "train_folders = folders[:150]\n",
        "val_folders = folders[150:180]\n",
        "test_folders = folders[180:]\n",
        "\n",
        "# Create dataset instances\n",
        "train_dataset = Sereact3DDataset(train_folders, transform=train_transform)\n",
        "val_dataset   = Sereact3DDataset(val_folders, transform=val_transform)\n",
        "test_dataset  = Sereact3DDataset(test_folders, transform=val_transform)\n",
        "\n",
        "# Custom collate function: if stacking fails, return a list.\n",
        "def custom_collate(batch):\n",
        "    collated = {}\n",
        "    for key in batch[0]:\n",
        "        try:\n",
        "            collated[key] = torch.stack([item[key] for item in batch])\n",
        "        except RuntimeError:\n",
        "            collated[key] = [item[key] for item in batch]\n",
        "    return collated\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=custom_collate)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=custom_collate)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=custom_collate)\n"
      ],
      "metadata": {
        "id": "9e2FumcUKVhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Define the Model"
      ],
      "metadata": {
        "id": "iVMHTYD7KcEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "class Simple3DBBoxModel(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super(Simple3DBBoxModel, self).__init__()\n",
        "        # Load ResNet18 using weights to avoid deprecated \"pretrained\" parameter.\n",
        "        resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.rgb_backbone = nn.Sequential(*list(resnet.children())[:-1])  # Output: [B, 512, 1, 1]\n",
        "\n",
        "        # MLP branch for point cloud (each point expected to have 3 features)\n",
        "        self.pc_branch = nn.Sequential(\n",
        "            nn.Linear(3, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Fusion and regression head (predicts 7 parameters: x, y, z, dx, dy, dz, heading)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512 + 256, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 7)\n",
        "        )\n",
        "\n",
        "    def forward(self, rgb, point_cloud):\n",
        "        # Process RGB branch.\n",
        "        x_rgb = self.rgb_backbone(rgb)         # [B, 512, 1, 1]\n",
        "        x_rgb = x_rgb.view(x_rgb.size(0), -1)    # [B, 512]\n",
        "\n",
        "        # Process point cloud branch.\n",
        "        if isinstance(point_cloud, list):\n",
        "            pc_feats = []\n",
        "            for pc in point_cloud:\n",
        "                # Remove extra singleton dimensions if present.\n",
        "                while pc.dim() > 2:\n",
        "                    pc = pc.squeeze(0)\n",
        "                # Now, expect pc to be of shape [N, 3]\n",
        "                if pc.dim() != 2 or pc.shape[1] != 3:\n",
        "                    raise ValueError(f\"Unexpected point cloud shape: {pc.shape}\")\n",
        "                N, C = pc.shape\n",
        "                pc_flat = pc.view(N, C)\n",
        "                feats = self.pc_branch(pc_flat)  # [N, 256]\n",
        "                feats = feats.mean(dim=0)         # Global feature: [256]\n",
        "                pc_feats.append(feats)\n",
        "            pc_feats = torch.stack(pc_feats, dim=0)  # [B, 256]\n",
        "        else:\n",
        "            # If already stacked: expected shape [B, N, 3]\n",
        "            B, N, C = point_cloud.shape\n",
        "            pc_flat = point_cloud.view(B * N, C)\n",
        "            pc_feats = self.pc_branch(pc_flat)       # [B*N, 256]\n",
        "            pc_feats = pc_feats.view(B, N, -1).mean(dim=1)  # [B, 256]\n",
        "\n",
        "        # Fuse features and predict.\n",
        "        fused = torch.cat([x_rgb, pc_feats], dim=1)  # [B, 768]\n",
        "        out = self.fc(fused)                          # [B, 7]\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "KFdtCOHQKlfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Loss & Training Routine"
      ],
      "metadata": {
        "id": "uYt5NglvKr5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def bbox3d_loss(pred, target):\n",
        "    return F.smooth_l1_loss(pred, target)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device='cuda'):\n",
        "    model = model.to(device)\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0.0\n",
        "        for batch in train_loader:\n",
        "            rgb = batch['rgb'].to(device)\n",
        "            # Leave point_cloud as a list if variable-sized.\n",
        "            pc = batch['point_cloud']\n",
        "            gt_bbox = batch['bbox3d']\n",
        "            optimizer.zero_grad()\n",
        "            if not isinstance(gt_bbox, list):\n",
        "                gt_bbox = gt_bbox.to(device)\n",
        "            pred_bbox = model(rgb, pc)\n",
        "            loss = criterion(pred_bbox, gt_bbox.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        total_val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                rgb = batch['rgb'].to(device)\n",
        "                pc = batch['point_cloud']\n",
        "                gt_bbox = batch['bbox3d']\n",
        "                if not isinstance(gt_bbox, list):\n",
        "                    gt_bbox = gt_bbox.to(device)\n",
        "                pred_bbox = model(rgb, pc)\n",
        "                val_loss = criterion(pred_bbox, gt_bbox.to(device))\n",
        "                total_val_loss += val_loss.item()\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    return train_losses, val_losses\n"
      ],
      "metadata": {
        "id": "dYhzHIRjKvK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Launch Training"
      ],
      "metadata": {
        "id": "SZd2_AMXK0ZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = Simple3DBBoxModel(pretrained=True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = bbox3d_loss\n",
        "\n",
        "train_losses, val_losses = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, device=device)\n"
      ],
      "metadata": {
        "id": "C-GkqY6OQea6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}