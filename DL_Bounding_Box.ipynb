{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNy4ilz/7T2a4w8n69se7e8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamt2897/DL_BB/blob/main/DL_Bounding_Box.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Dependencies"
      ],
      "metadata": {
        "id": "3tKJnSmfA-C4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch torchvision\n",
        "!pip install numpy matplotlib albumentations kornia open3d gdown\n",
        "\n"
      ],
      "metadata": {
        "id": "3HMn7e87_MyT",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download & Extract Your Dataset"
      ],
      "metadata": {
        "id": "ANieU6P-BLA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download from Google Drive using gdown\n",
        "!gdown \"https://drive.google.com/uc?id=11s-GLb6LZ0SCAVW6aikqImuuQEEbT_Fb\" -O dl_challenge.tar.xz\n",
        "\n",
        "# Extract the .tar.xz file\n",
        "!tar -xvf dl_challenge.tar.xz  # This should create a dl_challenge/ directory\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "amHMCWfcBN7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "data_dir = 'dl_challenge'  # or the path where dl_challenge is located\n",
        "folders = sorted(glob.glob(os.path.join(data_dir, '*')))\n",
        "print(\"Number of data folders:\", len(folders))\n",
        "print(\"First folder name:\", folders[0])\n",
        "print(\"Files in the first folder:\", os.listdir(folders[0]))\n",
        "\n"
      ],
      "metadata": {
        "id": "-IfO0WsvDXt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset & Preprocessing**"
      ],
      "metadata": {
        "id": "dWR0za-UEWXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_path = 'dl_challenge/96e66c6d-9915-11ee-9103-bbb8eae05561'\n",
        "print(\"Files in the folder:\", os.listdir(folder_path))\n"
      ],
      "metadata": {
        "id": "q5K0nciQKBxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Loading, Model Definition & Training Setup**"
      ],
      "metadata": {
        "id": "vB5-BJNIKG4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Create a PyTorch Dataset Class"
      ],
      "metadata": {
        "id": "vInKbRiOKNTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class Sereact3DDataset(Dataset):\n",
        "    def __init__(self, folder_list, transform=None):\n",
        "        self.folder_list = folder_list\n",
        "        self.transform = transform\n",
        "\n",
        "        # Filter folders to include only those with all required files.\n",
        "        self.folder_list = [\n",
        "            folder for folder in self.folder_list\n",
        "            if all(os.path.isfile(os.path.join(folder, fname))\n",
        "                   for fname in ['rgb.jpg', 'bbox3d.npy', 'mask.npy', 'pc.npy'])\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.folder_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        folder_path = self.folder_list[idx]\n",
        "        rgb_path   = os.path.join(folder_path, 'rgb.jpg')\n",
        "        bbox_path  = os.path.join(folder_path, 'bbox3d.npy')\n",
        "        mask_path  = os.path.join(folder_path, 'mask.npy')\n",
        "        pc_path    = os.path.join(folder_path, 'pc.npy')\n",
        "\n",
        "        # Load files\n",
        "        rgb = cv2.imread(rgb_path)[:, :, ::-1]  # Convert BGR to RGB\n",
        "        bbox3d = np.load(bbox_path)\n",
        "        mask = np.load(mask_path)\n",
        "        point_cloud = np.load(pc_path)\n",
        "\n",
        "        # If the point cloud looks like an image (shape: [3, H, W]), convert it.\n",
        "        if point_cloud.ndim == 3 and point_cloud.shape[0] == 3:\n",
        "            # Convert from (3, H, W) to (H, W, 3) then flatten to (H*W, 3)\n",
        "            point_cloud = np.transpose(point_cloud, (1, 2, 0))\n",
        "            point_cloud = point_cloud.reshape(-1, 3)\n",
        "\n",
        "        # Apply transform to RGB image if provided.\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=rgb)\n",
        "            rgb = augmented['image']\n",
        "\n",
        "        # Convert to torch tensors\n",
        "        rgb = torch.from_numpy(rgb).permute(2, 0, 1).float()  # (C, H, W)\n",
        "        bbox3d = torch.from_numpy(bbox3d).float()\n",
        "        mask = torch.from_numpy(mask).float()\n",
        "        point_cloud = torch.from_numpy(point_cloud).float()  # Expected shape: [N, 3]\n",
        "\n",
        "        return {\n",
        "            'rgb': rgb,\n",
        "            'bbox3d': bbox3d,\n",
        "            'mask': mask,\n",
        "            'point_cloud': point_cloud\n",
        "        }\n"
      ],
      "metadata": {
        "id": "lHnjAKGYKH-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Transforms and Create DataLoaders**"
      ],
      "metadata": {
        "id": "5XOpEesiKVIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from torch.utils.data import DataLoader\n",
        "import albumentations as A\n",
        "\n",
        "# Define transforms for training and validation.\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "])\n",
        "val_transform = A.Compose([A.Resize(224, 224)])\n",
        "\n",
        "# Get list of folders from 'dl_challenge'\n",
        "data_dir = 'dl_challenge'\n",
        "folders = sorted(glob.glob(os.path.join(data_dir, '*')))\n",
        "\n",
        "# Example splits (adjust counts as needed)\n",
        "train_folders = folders[:150]\n",
        "val_folders = folders[150:180]\n",
        "test_folders = folders[180:]\n",
        "\n",
        "# Create dataset instances\n",
        "train_dataset = Sereact3DDataset(train_folders, transform=train_transform)\n",
        "val_dataset   = Sereact3DDataset(val_folders, transform=val_transform)\n",
        "test_dataset  = Sereact3DDataset(test_folders, transform=val_transform)\n",
        "\n",
        "import torch\n",
        "\n",
        "def convert_bbox_corners_to_params(corners):\n",
        "    \"\"\"\n",
        "    Converts bounding box corners (tensor of shape [8, 3]) to a 7-parameter vector.\n",
        "    For demonstration purposes:\n",
        "      - Center is computed as the mean of the corners.\n",
        "      - Dimensions are computed as the difference between the max and min along each axis.\n",
        "      - Heading is set to 0.\n",
        "    Returns a tensor of shape [7].\n",
        "    \"\"\"\n",
        "    center = corners.mean(dim=0)  # [3]\n",
        "    dims = corners.max(dim=0)[0] - corners.min(dim=0)[0]  # [3]\n",
        "    heading = torch.tensor([0.0], device=corners.device)  # [1]\n",
        "    return torch.cat([center, dims, heading], dim=0)  # [7]\n",
        "\n",
        "def custom_collate(batch):\n",
        "    collated = {}\n",
        "    for key in batch[0]:\n",
        "        if key == 'bbox3d':\n",
        "            # For each sample, take the first bounding box and convert its corners to a 7-parameter vector.\n",
        "            collated[key] = torch.stack([convert_bbox_corners_to_params(item[key][0]) for item in batch])\n",
        "        else:\n",
        "            try:\n",
        "                collated[key] = torch.stack([item[key] for item in batch])\n",
        "            except RuntimeError:\n",
        "                collated[key] = [item[key] for item in batch]\n",
        "    return collated\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=custom_collate)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=custom_collate)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=custom_collate)\n"
      ],
      "metadata": {
        "id": "9e2FumcUKVhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Define the Model"
      ],
      "metadata": {
        "id": "iVMHTYD7KcEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "class Simple3DBBoxModel(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super(Simple3DBBoxModel, self).__init__()\n",
        "        resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.rgb_backbone = nn.Sequential(*list(resnet.children())[:-1])  # [B, 512, 1, 1]\n",
        "\n",
        "        self.pc_branch = nn.Sequential(\n",
        "            nn.Linear(3, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512 + 256, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 7)\n",
        "        )\n",
        "\n",
        "    def forward(self, rgb, point_cloud):\n",
        "        x_rgb = self.rgb_backbone(rgb)         # [B, 512, 1, 1]\n",
        "        x_rgb = x_rgb.view(x_rgb.size(0), -1)    # [B, 512]\n",
        "\n",
        "        if isinstance(point_cloud, list):\n",
        "            pc_feats = []\n",
        "            device_here = x_rgb.device\n",
        "            for pc in point_cloud:\n",
        "                pc = pc.to(device_here)  # Ensure tensor is on GPU\n",
        "                while pc.dim() > 2:\n",
        "                    pc = pc.squeeze(0)\n",
        "                if pc.dim() != 2 or pc.shape[1] != 3:\n",
        "                    raise ValueError(f\"Unexpected point cloud shape: {pc.shape}\")\n",
        "                N, C = pc.shape\n",
        "                pc_flat = pc.view(N, C)\n",
        "                feats = self.pc_branch(pc_flat)  # [N, 256]\n",
        "                feats = feats.mean(dim=0)         # [256]\n",
        "                pc_feats.append(feats)\n",
        "            pc_feats = torch.stack(pc_feats, dim=0)  # [B, 256]\n",
        "        else:\n",
        "            B, N, C = point_cloud.shape\n",
        "            point_cloud = point_cloud.to(x_rgb.device)\n",
        "            pc_flat = point_cloud.view(B * N, C)\n",
        "            pc_feats = self.pc_branch(pc_flat)\n",
        "            pc_feats = pc_feats.view(B, N, -1).mean(dim=1)  # [B, 256]\n",
        "\n",
        "        fused = torch.cat([x_rgb, pc_feats], dim=1)  # [B, 768]\n",
        "        out = self.fc(fused)                          # [B, 7]\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "KFdtCOHQKlfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Loss & Training Routine"
      ],
      "metadata": {
        "id": "uYt5NglvKr5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def bbox3d_loss(pred, target):\n",
        "    return F.smooth_l1_loss(pred, target)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device='cuda'):\n",
        "    model = model.to(device)\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0.0\n",
        "        for batch in train_loader:\n",
        "            rgb = batch['rgb'].to(device)\n",
        "            # Leave point_cloud as a list if variable-sized.\n",
        "            pc = batch['point_cloud']\n",
        "            gt_bbox = batch['bbox3d']\n",
        "            optimizer.zero_grad()\n",
        "            if not isinstance(gt_bbox, list):\n",
        "                gt_bbox = gt_bbox.to(device)\n",
        "            pred_bbox = model(rgb, pc)\n",
        "            loss = criterion(pred_bbox, gt_bbox.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        total_val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                rgb = batch['rgb'].to(device)\n",
        "                pc = batch['point_cloud']\n",
        "                gt_bbox = batch['bbox3d']\n",
        "                if not isinstance(gt_bbox, list):\n",
        "                    gt_bbox = gt_bbox.to(device)\n",
        "                pred_bbox = model(rgb, pc)\n",
        "                val_loss = criterion(pred_bbox, gt_bbox.to(device))\n",
        "                total_val_loss += val_loss.item()\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    return train_losses, val_losses\n"
      ],
      "metadata": {
        "id": "dYhzHIRjKvK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Launch Training"
      ],
      "metadata": {
        "id": "SZd2_AMXK0ZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = Simple3DBBoxModel(pretrained=True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = bbox3d_loss\n",
        "\n",
        "train_losses, val_losses = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "C-GkqY6OQea6",
        "outputId": "3f4776bf-cc97-4f94-d827-6562678e73c3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: uncorrectable ECC error encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-cfbcb1047fb9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox3d_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-4cb314482527>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1341\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1327\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     )\n\u001b[0;32m-> 1329\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1330\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: uncorrectable ECC error encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    }
  ]
}